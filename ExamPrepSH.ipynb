{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Exam for Deep Network Development course. First part (mandatory)**"
      ],
      "metadata": {
        "id": "hY88PZuGRlvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the task to be solved in order to pass the exam.\n",
        "This is the first part of the exam, which is compulsory in order to get a grade. It contains a task similar to what you have worked on during the semester, which consists on implementing a network architecture and a function.\n",
        "\n",
        "Please note that, to **PASS** the Deep Network Development course you must **SUBMIT A SUCCESSFUL SOLUTION FOR THE FIRST PART**. If you **FAIL** the first part, you have the right to do the exam **ONE MORE TIME**. If you **FAIL AGAIN**, then unfortunately, you have failed the course. If you **PASS** the first part, then you get the weighted average of your quizzes and assignments as your final grade."
      ],
      "metadata": {
        "id": "994g3vW4RpXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Your information\n",
        "Please fill the next cell with your information"
      ],
      "metadata": {
        "id": "KhN7-a6UiJjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Full Name**:\n",
        "\n"
      ],
      "metadata": {
        "id": "4cdkqW9sGOoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task Description"
      ],
      "metadata": {
        "id": "krzdzOL0Sejg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your task is to implement a custom architecture inspired by an Autoencoder model, and the forward function. The model receives an image as input and reconstructs the image as output.\n",
        "\n",
        "#### Afterwards, make sure to run cell code number 1.2. to check if your implementation is correct.\n",
        "\n",
        "#### This task should be **SOLVED IN 1 HOUR** and submitted to Canvas (download the .ipynb file). Please note that after 1 hour, the Canvas exam assignment will be closed and you cannot submit your solution."
      ],
      "metadata": {
        "id": "vjArI5jdUlLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "8Qn8jLgy81ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **NO GPU IS NEEDED for this task**. No training nor any computationally expensive operation will be performed. This notebook runs on any computer using a cpu."
      ],
      "metadata": {
        "id": "ztfR3038icfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #make sure that you are using GPU acceleration\n",
        "# device"
      ],
      "metadata": {
        "id": "ExK30uAjUaz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Architecture"
      ],
      "metadata": {
        "id": "3jPxTombVv9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Please keep in mind that this architecture is purely imagined and should not correspond to any existing model / architecture. You will not find it on the internet."
      ],
      "metadata": {
        "id": "vchO-YTwe38A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please right click the image and \"Open image in a new tab\" to view it better with zoom. Or download it from here: https://drive.google.com/file/d/1OnsE2YUgaorK2_36C2jQ8qwtoJizvclQ/view?usp=sharing\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1OnsE2YUgaorK2_36C2jQ8qwtoJizvclQ)"
      ],
      "metadata": {
        "id": "nwkZf0__hy2U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1. Implement the architecture"
      ],
      "metadata": {
        "id": "wtvGCndKhzhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Wwn11gARdQr"
      },
      "outputs": [],
      "source": [
        "class Reconstruct(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Reconstruct, self).__init__()\n",
        "\n",
        "        # DEFINE the layers\n",
        "\n",
        "        self.conv_A = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5, 5), stride=(2, 2), padding='valid')\n",
        "\n",
        "        self.maxpool_A = nn.MaxPool2d(kernel_size=(7,7), stride=(2,2))\n",
        "\n",
        "        self.conv_B = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), stride=(1, 1), padding='same')\n",
        "\n",
        "        self.maxpool_B = nn.MaxPool2d(kernel_size=(3,3), stride=(2,2))\n",
        "\n",
        "        self.conv_C = nn.Conv2d(in_channels=128, out_channels=512, kernel_size=(5, 5), stride=(3, 3), padding='valid')\n",
        "\n",
        "        self.convTrans_A = nn.ConvTranspose2d(in_channels=512, out_channels=512, kernel_size=(14, 14), stride=(7, 7), padding=2)\n",
        "\n",
        "        self.conv_D = nn.Conv2d(in_channels=640, out_channels=512, kernel_size=(3, 3), stride=(1, 1), padding='same')\n",
        "\n",
        "        self.convTrans_B = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=(8, 8), stride=(2, 2), padding=0)\n",
        "        self.convTrans_C = nn.ConvTranspose2d(in_channels=320, out_channels=3, kernel_size=(6, 6), stride=(2, 2), padding=0)\n",
        "\n",
        "       # SEND the input to the convolutional and max pooling layers\n",
        "\n",
        "    def forward(self, images):\n",
        "        outConv_A = self.conv_A(images)\n",
        "        outPool = self.maxpool_A(outConv_A)\n",
        "        outConv_B = self.conv_B(outPool)\n",
        "        outPool_B = self.maxpool_A(outConv_B)\n",
        "        outConv_C = self.conv_C(outPool_B)\n",
        "\n",
        "        # SEND the features from the previous layers to the convolutional and transposed convolutional layers.Combine the outputs.\n",
        "\n",
        "        outTran_A = self.convTrans_A(outConv_C)\n",
        "        print(\"outTran_A\", outTran_A.shape)\n",
        "        cat_A = torch.cat((outConv_B, outTran_A), dim=1)\n",
        "        print(\"cat_A\", cat_A.shape)\n",
        "        outConv_D = self.conv_D(cat_A)\n",
        "        print(\"outConv_D\", outConv_D.shape)\n",
        "        outTran_B = self.convTrans_B(outConv_D)\n",
        "        print(\"outTran_B\", outTran_B.shape)\n",
        "        cat_B = torch.cat((outConv_A, outTran_B), dim=1)\n",
        "        print(\"catb\", cat_B.shape)\n",
        "        outTran_C = self.convTrans_C(cat_B)\n",
        "        print(\"outTran_C\", outTran_C.shape)\n",
        "\n",
        "        return outTran_C #replace by actual output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Test your implementation.\n",
        "Expected output\n",
        "\n",
        "torch.Size( [1, 3, 224, 224] )"
      ],
      "metadata": {
        "id": "i_CJ9S9XzzT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image = torch.randn(1,3,224,224)\n",
        "\n",
        "custom = Reconstruct()\n",
        "output = custom(input_image)\n",
        "\n",
        "print(\"Your output shape is \", output.shape)\n",
        "\n",
        "assert output.shape == input_image.shape , \"Your implementation is INCORRECT!\"\n",
        "\n",
        "print(\"Your implementation is CORRECT!\")"
      ],
      "metadata": {
        "id": "8W2MQrYrxSHx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee85489-314c-49ed-f11d-f118f97f9fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outTran_A torch.Size([1, 512, 52, 52])\n",
            "cat_A torch.Size([1, 640, 52, 52])\n",
            "outConv_D torch.Size([1, 512, 52, 52])\n",
            "outTran_B torch.Size([1, 256, 110, 110])\n",
            "catb torch.Size([1, 320, 110, 110])\n",
            "outTran_C torch.Size([1, 3, 224, 224])\n",
            "Your output shape is  torch.Size([1, 3, 224, 224])\n",
            "Your implementation is CORRECT!\n"
          ]
        }
      ]
    }
  ]
}